{
    "contents" : "# CleanTweets() - Takes the junk out of a vector of\nCleanTweets <- function(some_txt)\n{\n  some_txt <- iconv(some_txt, to='ASCII', sub='')\n  some_txt <- sub('â€”', '', some_txt)\n  some_txt = gsub(\"(RT|via)((?:\\\\b\\\\W*@\\\\w+)+)\", \"\", some_txt)\n  some_txt = gsub(\"@\\\\w+\", \"\", some_txt)\n  some_txt = gsub(\"[[:punct:]]\", \"\", some_txt)\n  some_txt = gsub(\"[[:digit:]]\", \"\", some_txt)\n  some_txt = gsub(\"http\\\\w+\", \"\", some_txt)\n  some_txt = gsub(\"[ \\t]{2,}\", \"\", some_txt)\n  some_txt = gsub(\"^\\\\s+|\\\\s+$\", \"\", some_txt)\n  some_txt <- sub('\\n', '', some_txt)\n  \n  # define \"tolower error handling\" function\n  try.tolower = function(x)\n  {\n    y = NA\n    try_error = tryCatch(tolower(x), error=function(e) e)\n    if (!inherits(try_error, \"error\"))\n      y = tolower(x)\n    return(y)\n  }\n  \n  some_txt = sapply(some_txt, try.tolower)\n  some_txt = some_txt[some_txt != \"\"]\n  names(some_txt) = NULL\n  return(some_txt)\n}\n\nucfirst <- function(txt) {\n  uc_text <- paste(\n    u_to_upper_case(substring(txt, 1, 1)), \n    substring(txt, 2),\n    sep=\"\", collapse=\"\"\n  )\n  \n  return(uc_text)\n} \n\n\n####CODE From github\n##https://github.com/dirkchen/twitter-hashtag-analytics\nConstructCorpus <- function(textVec) {\n  \n  # Construct text corpus\n  text   <- c(textVec)\n  \n  more.stopwords <- c(\"via\", \"rt\", \"mt\", \"amp\")\n  \n  # create a object\n  corpus <- Corpus(VectorSource(text))\n  corpus <- tm_map(corpus, TrimToASCII)\n  corpus <- tm_map(corpus, TrimUrls)\n  \n  \n  #corpus <- tm_map(corpus, stripWhitespace) \n  \n  corpus <- tm_map(corpus, tolower)\n  corpus <- tm_map(corpus, TrimHtml)\n  \n  \n  corpus <- tm_map(corpus, TrimHashtags)\n  \n  corpus <- tm_map(corpus, TrimUsers)\n  \n  \n  \n  corpus <- tm_map(corpus, removePunctuation) \n  \n  \n  corpus <- tm_map(corpus, removeNumbers)\n  \n  \n  #corpus <- tm_map(corpus, removeWords, stopwords(\"english\")\n  corpus <- tm_map(corpus, function(x) \n    removeWords(x, append(stopwords(\"english\"), more.stopwords)))\n  \n  corpus <- tm_map(corpus, stripWhitespace)\n  corpus <- tm_map(corpus, TrimWhiteSpace)\n  return(corpus)\n}\n##!!!!check out this for future https://r-forge.r-project.org/scm/viewvc.php/pkg/wordcloud/R/cloud.R?view=markup&root=cens&pathrev=110\nMakeWordCloud <- function(words,freqs,titleName) { \n  # create document term matrix applying some transformations\n#   ap.tdm <- TermDocumentMatrix(corpus)\n#   ap.m <- as.matrix(ap.tdm)\n#   ap.v <- sort(rowSums(ap.m), decreasing=TRUE)\n#   ap.d <- data.frame(word = names(ap.v), freq=ap.v)\n#   table(ap.d$freq)\n  pal2 <- brewer.pal(8, \"Dark2\")\n  \n  \n  #fileName <- deparse(substitute(corpus))\n  # save the image in png format\n  png(titleName, width=12, height=8, units=\"in\", res=500)\n  layout(matrix(c(1, 2), nrow=2), heights=c(1, 4))\n  par(mar=rep(0, 4))\n  plot.new()\n  text(x=0.5, y=0.5, titleName)\n  wordcloud(ap.d$word, ap.d$freq, \n            scale=c(8, .8), min.freq = 3, \n            max.words = Inf, random.order = FALSE, \n            rot.per = .15, colors = pal2,main=\"Title\")\n  dev.off()\n}\nMakeComparisonWordCloud <- function(corpus,titleName) {\n  ap.tdm <- TermDocumentMatrix(Users.All.Corpus)\n  ap.m <- as.matrix(ap.tdm)\n  colnames(ap.m) = c(\"Cigar City\", \"Tampa Bay Brewing\", \"Boston Beer Co\",\"New Belgium Brewing Co\")\n  ap.v <- sort(rowSums(ap.m),decreasing=TRUE)\n  ap.d <- data.frame(word = names(ap.v),freq=ap.v)\n  table(ap.d$freq)\n  pal2 <- brewer.pal(8,\"Dark2\")\n  png(\"titleName\", width=12,height=8, units='in', res=300)\n  ###\n  layout(matrix(c(1, 2), nrow=2), heights=c(1, 4))\n  par(mar=rep(0, 4))\n  plot.new()\n  text(x=0.5, y=0.5, \"titleName\")\n  ###\n  comparison.cloud(ap.m, scale=c(4,.2),min.freq=3,\n                   max.words=Inf, random.order=FALSE, rot.per=.15,title.size=1.5, colors=pal2,main=\"Title\")\n  dev.off()\n}\n\nMakeCommonWordCloud <- function(matrix,titleName) {\n  ap.tdm <- TermDocumentMatrix(Users.All.Corpus)\n  ap.m <- as.matrix(ap.tdm)\n  \n  #fileName <- deparse(substitute(corpus))\n  # save the image in png format\n  png(titleName, width=12, height=8, units=\"in\", res=500)\n  layout(matrix(c(1, 2), nrow=2), heights=c(1, 4))\n  par(mar=rep(0, 4))\n  plot.new()\n  text(x=0.5, y=0.5, titleName)\n  #wordcloud(ap.d$word, ap.d$freq, \n  #         scale=c(8, .4), min.freq = 5, \n  #        max.words = 500, random.order = FALSE, \n  #       rot.per = .15,title.size=1.5, colors = pal2,main=\"Title\")\n  \n  commonality.cloud(ap.m, random.order=FALSE, \n                    colors = brewer.pal(8, \"Dark2\"))\n  \n  #commonality.cloud(ap.d$word, ap.d$freq, \n  #    scale=c(8, .4), min.freq = 5, \n  #   max.words = 500, random.order = FALSE, \n  #    rot.per = .15, colors = pal2,main=\"Title\")\n  # commonality.cloud(matrix, random.order=FALSE, \n  #                 colors = c(\"#00B2FF\", \"red\", \"#FF0099\", \"#6600CC\"),\n  #                max.words=500,main=\"Title\")\n  dev.off()\n}\n\n########Trim Strings\nTrimAt <- function(x) {\n  # remove @ from text\n  \n  sub('@', '', x)\n}\nTrimUTF <- function(x) {\n  # remove @ from text\n  \n  iconv(x, \"UTF-8\", \"UTF-8\")\n}\nTrimHtml <- function(x) {\n  # remove @ from text\n  \n  sub('â€”', '', x)\n}\n\nTrimToASCII <- function(x) {\n  # remove @ from text\n  \n  iconv(x, to='ASCII', sub='')\n}\n\n\nTrimHead <- function(x) {\n  # remove starting @, .@, RT @, MT @, etc.\n  \n  sub('^(.*)?@', '', x)\n}\n\nTrimUsers <- function(x) {\n  # remove users, i.e. \"@user\", in a tweet\n  \n  str_replace_all(x, '(@[[:alnum:]_]*)', '')\n}\n\nTrimHashtags <- function(x) {\n  # remove hashtags, i.e. \"#tag\", in a tweet\n  \n  str_replace_all(x, '(#[[:alnum:]_]*)', '')\n}\n\nTrimUrls <- function(x) {\n  # remove urls in a tweet\n  \n  str_replace_all(x, 'http[^[:blank:]]+', '')\n}\n\nTrimOddChar <- function(x) {\n  # remove odd charactors\n  iconv(x, to = 'UTF-8')\n}\nTrimWhiteSpace <- function(x) {\n  # remove odd charactors\n  # returns string w/o leading whitespace\n  x <- sub(\"^\\\\s+\", \"\", x)\n  # returns string w/o trailing whitespace\n  sub(\"\\\\s+$\", \"\", x)\n}\nbytecode.convert <- function(x) {iconv(enc2utf8(x), sub = \"byte\")}",
    "created" : 1410145496334.000,
    "dirty" : false,
    "encoding" : "UTF-8",
    "folds" : "",
    "hash" : "839685603",
    "id" : "33CC39B6",
    "lastKnownWriteTime" : 1410157683,
    "path" : "D:/Business/SameAndGregVenture/WeddingWordCloud/CloudUtils.R",
    "properties" : {
        "tempName" : "Untitled1"
    },
    "source_on_save" : false,
    "type" : "r_source"
}